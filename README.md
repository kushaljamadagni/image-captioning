# image-captioning
this is a model where images can be inputed and the captions would be generated
the image-captioning(1) is a model of image captioning which uses inceptionv3 for the processing of the images and uses an encoder decoder model with attention mechanism to train the model this model has a loss factor of 0.3 at the end of 15 epochs .this model does generate captions but the sentence formation of the captions is not soo great so we developed another model.




![model1](https://user-images.githubusercontent.com/55068834/121905471-d089dc80-cd47-11eb-8bfe-79dcf5f68597.jpg)




this image gives the loss function vs the epochs performed





![a](https://user-images.githubusercontent.com/55068834/121905746-19419580-cd48-11eb-9ec5-d21246981583.jpg)




this image gives the comparison between actual caption and predicted caption when it is tested on an image in the dataset




![b](https://user-images.githubusercontent.com/55068834/121906007-51e16f00-cd48-11eb-9dff-bdb77efeb0e5.jpg)




this image shows the caption generated when it is tested on a random image from the internet.
