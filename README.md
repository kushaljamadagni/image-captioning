# image-captioning
this is a model where images can be inputed and the captions would be generated
the image-captioning(1) is a model of image captioning which uses inceptionv3 for the processing of the images and uses an encoder decoder model with attention mechanism to train the model this model has a loss factor of 0.3 at the end of 15 epochs .this model does generate captions but the sentence formation of the captions is not soo great so we developed another model.




![model1](https://user-images.githubusercontent.com/55068834/121905471-d089dc80-cd47-11eb-8bfe-79dcf5f68597.jpg)




this image gives the loss function vs the epochs performed
